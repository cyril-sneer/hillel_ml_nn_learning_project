{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2288f9eb9902deb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:01:57.182791413Z",
     "start_time": "2024-02-24T15:01:56.523691337Z"
    }
   },
   "id": "b8f6cfccac9fbe14",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load models and tokenizers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f0df71a562f61cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizers = {\n",
    "    'eng': AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-uk\"),\n",
    "    'ukr': AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-uk-en\")\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:45:06.515964515Z",
     "start_time": "2024-02-24T15:45:05.709430588Z"
    }
   },
   "id": "34e6ae0af0afe659",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-uk.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-uk-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"eng\": TFAutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-uk\"),\n",
    "    \"ukr\": TFAutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-uk-en\")\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:45:14.017617253Z",
     "start_time": "2024-02-24T15:45:08.666387678Z"
    }
   },
   "id": "c53bfb811ab721cd",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define translation routine"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee4754b5e23b6b33"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def translate(input_text, tokenizer, model):\n",
    "    \n",
    "    # 1. Токенайзер переводит исходный текст в вектор\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"tf\")\n",
    "    \n",
    "    # 2. Модель делает перевод и возвращает вектор для фразы на целевом языке\n",
    "    outputs = model.generate(input_ids)\n",
    "    \n",
    "    # 3. Токенайзер декодирует вектор во фрацу на целевом языке\n",
    "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translated_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:52:49.515465287Z",
     "start_time": "2024-02-24T15:52:49.504383822Z"
    }
   },
   "id": "3d72e34ea29a5ca4",
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "# English -> Ukrainian"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dae3ac5270a62f74"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "translate_from = 'eng'\n",
    "\n",
    "tokenizer = tokenizers[translate_from]\n",
    "model = models[translate_from]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:52:46.395772635Z",
     "start_time": "2024-02-24T15:52:46.353971886Z"
    }
   },
   "id": "e5472851d35474ce",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text_in_eng = \"\"\"\n",
    "Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. \n",
    "Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. \n",
    "These models support common tasks in different modalities, such as:\n",
    "\n",
    "Natural Language Processing: \n",
    "text classification, named entity recognition, question answering, language modeling, summarization, translation, multiple choice, and text generation.\n",
    "Computer Vision: image classification, object detection, and segmentation.\n",
    "Audio: automatic speech recognition and audio classification.\n",
    "Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:52:53.097378901Z",
     "start_time": "2024-02-24T15:52:53.087678386Z"
    }
   },
   "id": "f16746413e9ac384",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text_in_ukr = translate(input_text=text_in_eng, tokenizer=tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:53:54.481904109Z",
     "start_time": "2024-02-24T15:53:04.058252546Z"
    }
   },
   "id": "4be305a74141b96",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Трансформатори надають вам змогу з легкістю звантажувати і тренувати стандартні моделі. За допомогою попередньо підготовлених моделей ви можете зменшити ваші обчислювальні витрати, сліди вуглецю, а також зберегти час і ресурси, необхідні для того, щоб тренувати модель з нуля. Ці моделі підтримують спільні завдання у різних модулях, зокрема: орієнтація мови: класифікація тексту, розпізнавання сутностей, відповідь на питання, коментар до мови, резюме, переклад, вибір з декількох варіантів і створення тексту. Комп' ютерне бачення: класифікація зображень, визначення об' єктів і сегментація. Звук: автоматичне розпізнавання і класифікація звуку. Групове: відповідь на питання таблиці, оптичне розпізнавання символів, отримання інформації з сканованих документів, класифікації відео та візуальних питань.\n"
     ]
    }
   ],
   "source": [
    "print(text_in_ukr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:53:54.524422341Z",
     "start_time": "2024-02-24T15:53:54.523429475Z"
    }
   },
   "id": "ae08a64d5fe79c58",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ukrainian -> English"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da63fd510fda522b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "translate_from = 'ukr'\n",
    "\n",
    "tokenizer = tokenizers[translate_from]\n",
    "model = models[translate_from]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:54:08.300716424Z",
     "start_time": "2024-02-24T15:54:08.256024360Z"
    }
   },
   "id": "76c4634ab08be0ad",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text_in_eng = translate(input_text=text_in_ukr, tokenizer=tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:55:28.189733926Z",
     "start_time": "2024-02-24T15:54:46.994658174Z"
    }
   },
   "id": "b16574ee26ff1524",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers allow you to easily download and train standard models. With pre-trained models you can reduce your computational costs, carbon footprints, as well as save the time and resources needed to train the model from scratch. These models support common tasks in various modules, including: Language orientation: Text rating, Entity Authentication, Answer, Language Comment, Summary, Multiple Choices and Text Creation. Computer vision: Image classification, Object Definition, and Segment. Sound: Automatic audio recognition and audio classification. Group: Answer to Questions, Optical Character Authentication, get information from scanned documents, ratings, and visuals.\n"
     ]
    }
   ],
   "source": [
    "print(text_in_eng)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:55:28.232400605Z",
     "start_time": "2024-02-24T15:55:28.231438029Z"
    }
   },
   "id": "5e95bc18fb526e98",
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
